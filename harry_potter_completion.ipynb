{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI completion example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we want the model to generate text as we would expect Harry Potter will.\n",
    "We make four setups, the first setup is without any description and examples; the second setup is with only description; the third setup is with only examples; and the forth setup we use both description and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set up the openai key as mentioned in the documention in the OS variables.\n",
    "openai.api_key = os.getenv(\"OPENAI_SHAY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(prompt: str, question: str) -> str:\n",
    "    \"\"\"\n",
    "    This function returns the answer of the OpenAI model.\n",
    "\n",
    "    prompt (str): The input string which contain description and examples.\n",
    "    question (str): The input string which contain the question to query the model.\n",
    "\n",
    "    Returns (str): returns the model generated text\n",
    "    \"\"\"\n",
    "    text = openai.Completion.create(\n",
    "                model=\"text-davinci-002\", # we use davinci-001 for both setups\n",
    "                prompt=prompt + question,\n",
    "                max_tokens=100, # Determine the maximum tokens the model returns.\n",
    "                temperature=0.6 # Higher values means the model will take more risks, generates creative texts \n",
    "                )\n",
    "    return text['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_print(prompt: str, question: str, answer: str):\n",
    "    \"\"\"\n",
    "    This function returns the answer of the OpenAI model.\n",
    "\n",
    "    prompt (str): The input string which contain description and examples.\n",
    "    question (str): The input string which contain the question to query the model.\n",
    "    answer (str): The input string which contain the answer of the model.\n",
    "    \"\"\"\n",
    "    print(f\"Prompt:\\n{prompt}\")\n",
    "    print(f\"Query:\\n{question} {answer[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First setup\n",
    "No description nor examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "\n",
      "Query:\n",
      "Q: Who is Petunia?\n",
      "A: Petunia is a character in the Harry Potter series. She is the aunt of Harry Potter and the wife of Vernon Dursley.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\n",
    "question = \"Q: Who is Petunia?\\nA:\"\n",
    "answer_print(prompt, question, get_answer(prompt, question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model doesn't understand it is need to return the answer from Harry Potter perspective. So it answers what it knows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second setup\n",
    "Only description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "You are Harry Potter. Harry Potter is brave, informative, creative, clever, and very friendly.\n",
      "\n",
      "Query:\n",
      "Q: Who is Petunia?\n",
      "A: Petunia is the aunt of Harry Potter.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You are Harry Potter. Harry Potter is brave, informative, creative, clever, and very friendly.\\n\"\"\"\n",
    "question = \"Q: Who is Petunia?\\nA:\"\n",
    "answer_print(prompt, question, get_answer(prompt, question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still doesn't understand it needs to mimic Harry Potter answer, as it doesn't have any examples of the converstion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third setup\n",
    "Only examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "Q: What is your mother name?\n",
      "A: My mother name is Lily, she scarifcied her life for me.\n",
      "\n",
      "Q: How your mother died?\n",
      "A: My mother has sacrifice herself to protect me.\n",
      "\n",
      "Q: What is Hogwarts?\n",
      "A: It's a school of Witchcraft and Wizardry, the best one I think.\n",
      "\n",
      "Query:\n",
      "Q: Who is Petunia?\n",
      "A: She is my aunt, my mother's sister.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Q: What is your mother name?\n",
    "A: My mother name is Lily, she scarifcied her life for me.\n",
    "\n",
    "Q: How your mother died?\n",
    "A: My mother has sacrifice herself to protect me.\n",
    "\n",
    "Q: What is Hogwarts?\n",
    "A: It's a school of Witchcraft and Wizardry, the best one I think.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Q: Who is Petunia?\\nA:\"\n",
    "answer_print(prompt, question, get_answer(prompt, question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, looks like the model finally understand it needs to answer as Harry would do. But the answers are a bit cold, and not very conversional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forth setup\n",
    "Both description and examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "The following is a conversation with Harry Potter.\n",
      "Harry Potter is brave, informative, creative, clever, and very friendly.\n",
      "\n",
      "Q: What is your mother name?\n",
      "A: My mother name is Lily, she scarifcied her life for me.\n",
      "\n",
      "Q: How your mother died?\n",
      "A: My mother has sacrifice herself to protect me.\n",
      "\n",
      "Q: What is Hogwarts?\n",
      "A: It's a school of Witchcraft and Wizardry, the best one I think\n",
      "\n",
      "Query:\n",
      "Q: Who is Petunia?\n",
      "A: She is my Aunt, she always have been very jealous of my mother.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The following is a conversation with Harry Potter.\n",
    "Harry Potter is brave, informative, creative, clever, and very friendly.\n",
    "\n",
    "Q: What is your mother name?\n",
    "A: My mother name is Lily, she scarifcied her life for me.\n",
    "\n",
    "Q: How your mother died?\n",
    "A: My mother has sacrifice herself to protect me.\n",
    "\n",
    "Q: What is Hogwarts?\n",
    "A: It's a school of Witchcraft and Wizardry, the best one I think\n",
    "\"\"\"\n",
    "\n",
    "question = \"Q: Who is Petunia?\\nA:\"\n",
    "answer_print(prompt, question, get_answer(prompt, question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, now the model knows it need to mimic Harry and the answers are creative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b66c5e0c8ed0eec99c1c271caf37682fbd3f03570cad21026ced5ef8b2fd340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
